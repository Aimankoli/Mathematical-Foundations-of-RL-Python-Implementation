{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d212214-ae58-4729-9287-da5698c33fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in c:\\users\\maima\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\maima\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e4a7e4e-cda4-4504-a9ea-c53a92c831f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sme predefinitions to make takings actions easier\n",
    "L=0\n",
    "R=1\n",
    "U=2\n",
    "D=3\n",
    "S=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cb4aaed2-e77c-451b-b3b6-0fe448996736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from typing import List, Tuple, Iterable, Set\n",
    "\n",
    "Action = int  # alias for readability (0‑4)\n",
    "State  = int  # flattened index\n",
    "\n",
    "# Displacement vectors for actions: L, R, U, D, Stay\n",
    "_DRDC = [ (0, -1), (0, 1), (-1, 0), (1, 0), (0, 0) ]\n",
    "\n",
    "HOLE_REWARD  = -1.0\n",
    "GOAL_REWARD  = +1.0\n",
    "STEP_REWARD  =  0.0\n",
    "\n",
    "class GridWorld:\n",
    "    \"\"\"Deterministic tabular environment suitable for DP algorithms.\"\"\"\n",
    "    def __init__(self,\n",
    "                 rows: int,\n",
    "                 cols: int,\n",
    "                 start: Tuple[int, int],\n",
    "                 goal: Tuple[int, int],\n",
    "                 holes: Iterable[Tuple[int, int]] = ()):        \n",
    "        self.rows, self.cols = rows, cols\n",
    "        self.nS, self.nA = rows * cols, 5\n",
    "\n",
    "        # Helper lambdas ------------------------------------------------------\n",
    "        self._to_id   = lambda rc: rc[0] * self.cols + rc[1]\n",
    "        self._to_rc   = lambda s: divmod(s, self.cols)\n",
    "\n",
    "        # Convert & store special cells --------------------------------------\n",
    "        self.start: State = self._to_id(start)\n",
    "        self.goal:  State = self._to_id(goal)\n",
    "        self.holes: Set[State] = {self._to_id(h) for h in holes if h != goal and h != start}\n",
    "\n",
    "        # Tables --------------------------------------------------------------\n",
    "        self.next_state = np.zeros((self.nS, self.nA), dtype=np.int32)\n",
    "        self.reward     = np.zeros((self.nS, self.nA), dtype=np.float32)\n",
    "        self._build_transition_tables()\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    def _build_transition_tables(self):\n",
    "        for s in range(self.nS):\n",
    "            r, c = self._to_rc(s)\n",
    "            for a, (dr, dc) in enumerate(_DRDC):\n",
    "                nr, nc = r + dr, c + dc\n",
    "                # Off‑grid? => stay, reward -1\n",
    "                if nr < 0 or nr >= self.rows or nc < 0 or nc >= self.cols:\n",
    "                    self.next_state[s, a] = s\n",
    "                    self.reward[s, a]     = HOLE_REWARD  # same as off‑grid penalty\n",
    "                    continue\n",
    "\n",
    "                s_next = self._to_id((nr, nc))\n",
    "                self.next_state[s, a] = s_next\n",
    "\n",
    "                if s_next == self.goal:\n",
    "                    self.reward[s, a] = GOAL_REWARD\n",
    "                elif s_next in self.holes:\n",
    "                    self.reward[s, a] = HOLE_REWARD\n",
    "                else:\n",
    "                    self.reward[s, a] = STEP_REWARD\n",
    "\n",
    "    # ------------------------------------------------------------------ env API\n",
    "    def reset(self) -> State:\n",
    "        return self.start\n",
    "\n",
    "    def step(self, s: State, a: Action) -> Tuple[State, float]:\n",
    "        \"\"\"Return (next_state, reward).  No done flag because episodes never end.\"\"\"\n",
    "        return int(self.next_state[s, a]), float(self.reward[s, a])\n",
    "\n",
    "    # -------------------------------------------------------------- visualisation\n",
    "    def render(self, agent_state: State | None = None):\n",
    "        symbols = []\n",
    "        for s in range(self.nS):\n",
    "            if s == agent_state:\n",
    "                symbols.append(\"A\")\n",
    "            elif s == self.start:\n",
    "                symbols.append(\"S\")\n",
    "            elif s == self.goal:\n",
    "                symbols.append(\"G\")\n",
    "            elif s in self.holes:\n",
    "                symbols.append(\"H\")\n",
    "            else:\n",
    "                symbols.append(\"·\")\n",
    "        # reshape & draw ------------------------------------------------------\n",
    "        rows = [ symbols[i:i+self.cols] for i in range(0, self.nS, self.cols) ]\n",
    "        print(tabulate(rows, tablefmt=\"grid\"))\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Utility to build a random instance ----------------------------------------\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def make_random_grid(rows: int,\n",
    "                     cols: int,\n",
    "                     n_holes: int = 0,\n",
    "                     seed: int | None = None) -> GridWorld:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    all_cells = [(r, c) for r in range(rows) for c in range(cols)]\n",
    "    start = tuple(map(int, rng.choice(all_cells)))\n",
    "    remaining = [cell for cell in all_cells if cell != start]\n",
    "    goal  = tuple(map(int, rng.choice(remaining)))\n",
    "    remaining.remove(goal)\n",
    "    holes = [tuple(map(int, h)) for h in rng.choice(remaining, size=min(n_holes, len(remaining)), replace=False)]\n",
    "    return GridWorld(rows, cols, start, goal, holes)\n",
    "\n",
    "def show_table(mat, headers, title=\"\"):\n",
    "    rows = [[s, *mat[s]] for s in range(mat.shape[0])]\n",
    "    print(f\"\\n{title}\")\n",
    "    print(tabulate(rows,\n",
    "                   headers=[\"state\", *headers],\n",
    "                   floatfmt=\".1f\",\n",
    "                   tablefmt=\"grid\"))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "200e2088-0c38-4ab0-b0b8-b9a8c82a61e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+---+---+---+\n",
      "| · | · | H | · | · | · | · | · | · | · |\n",
      "+---+---+---+---+---+---+---+---+---+---+\n",
      "| · | · | · | · | · | · | · | · | · | · |\n",
      "+---+---+---+---+---+---+---+---+---+---+\n",
      "| · | · | · | · | · | · | · | · | · | · |\n",
      "+---+---+---+---+---+---+---+---+---+---+\n",
      "| · | · | · | · | · | · | · | · | · | · |\n",
      "+---+---+---+---+---+---+---+---+---+---+\n",
      "| · | · | H | · | · | · | · | · | · | · |\n",
      "+---+---+---+---+---+---+---+---+---+---+\n",
      "| · | · | · | · | · | · | S | · | · | · |\n",
      "+---+---+---+---+---+---+---+---+---+---+\n",
      "| · | · | · | · | · | · | · | · | H | · |\n",
      "+---+---+---+---+---+---+---+---+---+---+\n",
      "| · | · | · | G | · | · | · | · | · | · |\n",
      "+---+---+---+---+---+---+---+---+---+---+\n",
      "| · | · | · | · | · | · | · | · | · | · |\n",
      "+---+---+---+---+---+---+---+---+---+---+\n",
      "| · | · | · | · | · | · | · | · | · | · |\n",
      "+---+---+---+---+---+---+---+---+---+---+\n"
     ]
    }
   ],
   "source": [
    "env = make_random_grid(10, 10, n_holes=3, seed=40)\n",
    "env.render()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "937a6d29-937a-49fb-9d18-323fe189c898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "63cef0ad-81ef-4cfd-bfcb-30b5b2fb65fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reward table\n",
      "+---------+------+------+------+------+------+\n",
      "|   state |    L |    R |    U |    D |    S |\n",
      "+=========+======+======+======+======+======+\n",
      "|       0 | -2.0 |  0.0 | -2.0 |  0.0 | -2.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       1 | -2.0 |  0.0 | -2.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       2 |  0.0 |  0.0 | -2.0 | -2.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       3 |  0.0 | -2.0 | -2.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       4 | -2.0 |  0.0 | -2.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       5 |  0.0 | -2.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       6 |  0.0 |  0.0 |  0.0 | -2.0 | -2.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       7 | -2.0 | -2.0 |  0.0 |  1.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       8 | -2.0 |  0.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       9 |  0.0 | -2.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      10 |  0.0 |  1.0 | -2.0 |  0.0 | -2.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      11 | -2.0 | -2.0 |  0.0 |  0.0 |  1.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      12 | -2.0 |  0.0 |  0.0 | -2.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      13 |  0.0 |  0.0 |  0.0 | -2.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      14 |  0.0 |  0.0 | -2.0 | -2.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      15 |  0.0 | -2.0 |  1.0 | -2.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "\n",
      "Next-state table\n",
      "+---------+------+------+------+------+------+\n",
      "|   state |    L |    R |    U |    D |    S |\n",
      "+=========+======+======+======+======+======+\n",
      "|       0 |  0.0 |  1.0 |  0.0 |  4.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       1 |  0.0 |  2.0 |  1.0 |  5.0 |  1.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       2 |  1.0 |  3.0 |  2.0 |  6.0 |  2.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       3 |  2.0 |  3.0 |  3.0 |  7.0 |  3.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       4 |  4.0 |  5.0 |  0.0 |  8.0 |  4.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       5 |  4.0 |  6.0 |  1.0 |  9.0 |  5.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       6 |  5.0 |  7.0 |  2.0 | 10.0 |  6.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       7 |  6.0 |  7.0 |  3.0 | 11.0 |  7.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       8 |  8.0 |  9.0 |  4.0 | 12.0 |  8.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       9 |  8.0 | 10.0 |  5.0 | 13.0 |  9.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      10 |  9.0 | 11.0 |  6.0 | 14.0 | 10.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      11 | 10.0 | 11.0 |  7.0 | 15.0 | 11.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      12 | 12.0 | 13.0 |  8.0 | 12.0 | 12.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      13 | 12.0 | 14.0 |  9.0 | 13.0 | 13.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      14 | 13.0 | 15.0 | 10.0 | 14.0 | 14.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      15 | 14.0 | 15.0 | 11.0 | 15.0 | 15.0 |\n",
      "+---------+------+------+------+------+------+\n"
     ]
    }
   ],
   "source": [
    "acts = [\"L\", \"R\", \"U\", \"D\", \"S\"]\n",
    "show_table(env.reward,      acts, \"Reward table\")\n",
    "show_table(env.next_state,  acts, \"Next-state table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a01e5adb-869c-45b5-af59-43abfed441db",
   "metadata": {},
   "outputs": [],
   "source": [
    "discount = 0.8\n",
    "def init_v(env: GridWorld):\n",
    "    return np.zeros(env.nS)\n",
    "\n",
    "def init_pi(env: GridWorld):\n",
    "    pi = np.empty(env.nS)\n",
    "    for state in range(env.nS):\n",
    "        pi[state] = S\n",
    "    return pi\n",
    "        \n",
    "        \n",
    "def value_iteration(env: GridWorld):\n",
    "    #initialize current policy: Stay everywhere    \n",
    "    # pi is a nSx2 grid: for each state, what action we take. In this case, (0,0) for all\n",
    "    #initialize v = 0 for all S\n",
    "    # now make a q table with nSxnA\n",
    "    #loop over s\n",
    "        #for every a:\n",
    "            #q[s,a] = immediate reward for the action from reward table + discount rate x v(next state for that action)\n",
    "        #take maximum a and then set pi[s] = a\n",
    "        #then set v[s] to the return of chosing this max a\n",
    "\n",
    "    pi = init_pi(env)\n",
    "    v_table = init_v(env)\n",
    "    q_table = np.full((env.nS, env.nA), 0, dtype=float)\n",
    "    diff = float('inf')\n",
    "    while diff>0.01:\n",
    "        v_table_new = np.copy(v_table)\n",
    "        for state in range (env.nS):\n",
    "            max_reward = float('-inf')\n",
    "            for action in range (env.nA):\n",
    "                qvalue = env.reward[state][action] + discount*v_table[env.next_state[state][action]]\n",
    "                q_table[state][action] = qvalue\n",
    "                if qvalue>=max_reward:\n",
    "                    max_reward = qvalue\n",
    "                    pi[state] = action\n",
    "            v_table_new[state] = max_reward\n",
    "        diff = np.sum(np.absolute(v_table_new-v_table))\n",
    "        v_table = np.copy(v_table_new)\n",
    "\n",
    "    ##Recreate path\n",
    "    # path = recreate_path(pi, env)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return pi, v_table, q_table\n",
    "\n",
    "def recreate_path(pi: np.array, env: GridWorld):\n",
    "    path = np.zeros((env.rows,env.cols))\n",
    "    ctr = 0\n",
    "    for i in range(env.rows):\n",
    "        for j in range (env.cols):\n",
    "            path[i][j] = pi[ctr]\n",
    "            ctr+=1\n",
    "        \n",
    "    return path\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "286c9c49-4dda-40b2-83b5-70d84f148e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pi,vt,qt =value_iteration(env)\n",
    "path = recreate_path(pi, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e59dbe46-f83b-4532-9fee-bb6a27a75961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 3.]\n",
      " [3. 3. 1. 3.]\n",
      " [3. 3. 1. 4.]\n",
      " [1. 1. 1. 2.]]\n"
     ]
    }
   ],
   "source": [
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9f5132ab-a44b-4fcf-b4e3-4c60e5b20354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+\n",
      "| H | · | · | · |\n",
      "+---+---+---+---+\n",
      "| · | · | H | · |\n",
      "+---+---+---+---+\n",
      "| S | · | H | G |\n",
      "+---+---+---+---+\n",
      "| · | · | · | · |\n",
      "+---+---+---+---+\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "65a2527f-bcb1-4e87-bfe7-b8a7529cae62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.next_state[10][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b82091-2116-4b2f-85e3-429c9f928f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
