{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d212214-ae58-4729-9287-da5698c33fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in c:\\users\\maima\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\maima\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e4a7e4e-cda4-4504-a9ea-c53a92c831f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sme predefinitions to make takings actions easier\n",
    "L=0\n",
    "R=1\n",
    "U=2\n",
    "D=3\n",
    "S=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3ff4c5e-19f7-4e99-91cc-bd955d489a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "###_MAKING GRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb4aaed2-e77c-451b-b3b6-0fe448996736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from typing import List, Tuple, Iterable, Set\n",
    "\n",
    "Action = int  # alias for readability (0‑4)\n",
    "State  = int  # flattened index\n",
    "\n",
    "# Displacement vectors for actions: L, R, U, D, Stay\n",
    "_DRDC = [ (0, -1), (0, 1), (-1, 0), (1, 0), (0, 0) ]\n",
    "\n",
    "HOLE_REWARD  = -1.0\n",
    "GOAL_REWARD  = +1.0\n",
    "STEP_REWARD  =  0.0\n",
    "\n",
    "class GridWorld:\n",
    "    \"\"\"Deterministic tabular environment suitable for DP algorithms.\"\"\"\n",
    "    def __init__(self,\n",
    "                 rows: int,\n",
    "                 cols: int,\n",
    "                 start: Tuple[int, int],\n",
    "                 goal: Tuple[int, int],\n",
    "                 holes: Iterable[Tuple[int, int]] = ()):        \n",
    "        self.rows, self.cols = rows, cols\n",
    "        self.nS, self.nA = rows * cols, 5\n",
    "\n",
    "        # Helper lambdas ------------------------------------------------------\n",
    "        self._to_id   = lambda rc: rc[0] * self.cols + rc[1]\n",
    "        self._to_rc   = lambda s: divmod(s, self.cols)\n",
    "\n",
    "        # Convert & store special cells --------------------------------------\n",
    "        self.start: State = self._to_id(start)\n",
    "        self.goal:  State = self._to_id(goal)\n",
    "        self.holes: Set[State] = {self._to_id(h) for h in holes if h != goal and h != start}\n",
    "\n",
    "        # Tables --------------------------------------------------------------\n",
    "        self.next_state = np.zeros((self.nS, self.nA), dtype=np.int32)\n",
    "        self.reward     = np.zeros((self.nS, self.nA), dtype=np.float32)\n",
    "        self._build_transition_tables()\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    def _build_transition_tables(self):\n",
    "        for s in range(self.nS):\n",
    "            r, c = self._to_rc(s)\n",
    "            for a, (dr, dc) in enumerate(_DRDC):\n",
    "                nr, nc = r + dr, c + dc\n",
    "                # Off‑grid? => stay, reward -1\n",
    "                if nr < 0 or nr >= self.rows or nc < 0 or nc >= self.cols:\n",
    "                    self.next_state[s, a] = s\n",
    "                    self.reward[s, a]     = HOLE_REWARD  # same as off‑grid penalty\n",
    "                    continue\n",
    "\n",
    "                s_next = self._to_id((nr, nc))\n",
    "                self.next_state[s, a] = s_next\n",
    "\n",
    "                if s_next == self.goal:\n",
    "                    self.reward[s, a] = GOAL_REWARD\n",
    "                elif s_next in self.holes:\n",
    "                    self.reward[s, a] = HOLE_REWARD\n",
    "                else:\n",
    "                    self.reward[s, a] = STEP_REWARD\n",
    "\n",
    "    # ------------------------------------------------------------------ env API\n",
    "    def reset(self) -> State:\n",
    "        return self.start\n",
    "\n",
    "    def step(self, s: State, a: Action) -> Tuple[State, float]:\n",
    "        \"\"\"Return (next_state, reward).  No done flag because episodes never end.\"\"\"\n",
    "        return int(self.next_state[s, a]), float(self.reward[s, a])\n",
    "\n",
    "    # -------------------------------------------------------------- visualisation\n",
    "    def render(self, agent_state: State | None = None):\n",
    "        symbols = []\n",
    "        for s in range(self.nS):\n",
    "            if s == agent_state:\n",
    "                symbols.append(\"A\")\n",
    "            elif s == self.start:\n",
    "                symbols.append(\"S\")\n",
    "            elif s == self.goal:\n",
    "                symbols.append(\"G\")\n",
    "            elif s in self.holes:\n",
    "                symbols.append(\"H\")\n",
    "            else:\n",
    "                symbols.append(\"·\")\n",
    "        # reshape & draw ------------------------------------------------------\n",
    "        rows = [ symbols[i:i+self.cols] for i in range(0, self.nS, self.cols) ]\n",
    "        print(tabulate(rows, tablefmt=\"grid\"))\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Utility to build a random instance ----------------------------------------\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def make_random_grid(rows: int,\n",
    "                     cols: int,\n",
    "                     n_holes: int = 0,\n",
    "                     seed: int | None = None) -> GridWorld:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    all_cells = [(r, c) for r in range(rows) for c in range(cols)]\n",
    "    start = tuple(map(int, rng.choice(all_cells)))\n",
    "    remaining = [cell for cell in all_cells if cell != start]\n",
    "    goal  = tuple(map(int, rng.choice(remaining)))\n",
    "    remaining.remove(goal)\n",
    "    holes = [tuple(map(int, h)) for h in rng.choice(remaining, size=min(n_holes, len(remaining)), replace=False)]\n",
    "    return GridWorld(rows, cols, start, goal, holes)\n",
    "\n",
    "def show_table(mat, headers, title=\"\"):\n",
    "    rows = [[s, *mat[s]] for s in range(mat.shape[0])]\n",
    "    print(f\"\\n{title}\")\n",
    "    print(tabulate(rows,\n",
    "                   headers=[\"state\", *headers],\n",
    "                   floatfmt=\".1f\",\n",
    "                   tablefmt=\"grid\"))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "200e2088-0c38-4ab0-b0b8-b9a8c82a61e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+\n",
      "| H | H | H | · | · | · | · |\n",
      "+---+---+---+---+---+---+---+\n",
      "| · | · | · | · | · | · | · |\n",
      "+---+---+---+---+---+---+---+\n",
      "| · | · | · | · | H | · | · |\n",
      "+---+---+---+---+---+---+---+\n",
      "| H | · | · | · | · | · | S |\n",
      "+---+---+---+---+---+---+---+\n",
      "| · | H | · | · | · | H | · |\n",
      "+---+---+---+---+---+---+---+\n",
      "| · | G | · | · | · | · | · |\n",
      "+---+---+---+---+---+---+---+\n",
      "| H | · | · | · | · | · | · |\n",
      "+---+---+---+---+---+---+---+\n"
     ]
    }
   ],
   "source": [
    "env = make_random_grid(7, 7, n_holes=8, seed=40)\n",
    "env.render()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "937a6d29-937a-49fb-9d18-323fe189c898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "63cef0ad-81ef-4cfd-bfcb-30b5b2fb65fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reward table\n",
      "+---------+------+------+------+------+------+\n",
      "|   state |    L |    R |    U |    D |    S |\n",
      "+=========+======+======+======+======+======+\n",
      "|       0 | -1.0 | -1.0 | -1.0 |  0.0 | -1.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       1 | -1.0 | -1.0 | -1.0 |  0.0 | -1.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       2 | -1.0 |  0.0 | -1.0 |  0.0 | -1.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       3 | -1.0 |  0.0 | -1.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       4 |  0.0 |  0.0 | -1.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       5 |  0.0 |  0.0 | -1.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       6 |  0.0 | -1.0 | -1.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       7 | -1.0 |  0.0 | -1.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       8 |  0.0 |  0.0 | -1.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       9 |  0.0 |  0.0 | -1.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      10 |  0.0 |  0.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      11 |  0.0 |  0.0 |  0.0 | -1.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      12 |  0.0 |  0.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      13 |  0.0 | -1.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      14 | -1.0 |  0.0 |  0.0 | -1.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      15 |  0.0 |  0.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      16 |  0.0 |  0.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      17 |  0.0 | -1.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      18 |  0.0 |  0.0 |  0.0 |  0.0 | -1.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      19 | -1.0 |  0.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      20 |  0.0 | -1.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      21 | -1.0 |  0.0 |  0.0 |  0.0 | -1.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      22 | -1.0 |  0.0 |  0.0 | -1.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      23 |  0.0 |  0.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      24 |  0.0 |  0.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      25 |  0.0 |  0.0 | -1.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      26 |  0.0 |  0.0 |  0.0 | -1.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      27 |  0.0 | -1.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      28 | -1.0 | -1.0 | -1.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      29 |  0.0 |  0.0 |  0.0 |  1.0 | -1.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      30 | -1.0 |  0.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      31 |  0.0 |  0.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      32 |  0.0 | -1.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      33 |  0.0 |  0.0 |  0.0 |  0.0 | -1.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      34 | -1.0 | -1.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      35 | -1.0 |  1.0 |  0.0 | -1.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      36 |  0.0 |  0.0 | -1.0 |  0.0 |  1.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      37 |  1.0 |  0.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      38 |  0.0 |  0.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      39 |  0.0 |  0.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      40 |  0.0 |  0.0 | -1.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      41 |  0.0 | -1.0 |  0.0 |  0.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      42 | -1.0 |  0.0 |  0.0 | -1.0 | -1.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      43 | -1.0 |  0.0 |  1.0 | -1.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      44 |  0.0 |  0.0 |  0.0 | -1.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      45 |  0.0 |  0.0 |  0.0 | -1.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      46 |  0.0 |  0.0 |  0.0 | -1.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      47 |  0.0 |  0.0 |  0.0 | -1.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      48 |  0.0 | -1.0 |  0.0 | -1.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "\n",
      "Next-state table\n",
      "+---------+------+------+------+------+------+\n",
      "|   state |    L |    R |    U |    D |    S |\n",
      "+=========+======+======+======+======+======+\n",
      "|       0 |  0.0 |  1.0 |  0.0 |  7.0 |  0.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       1 |  0.0 |  2.0 |  1.0 |  8.0 |  1.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       2 |  1.0 |  3.0 |  2.0 |  9.0 |  2.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       3 |  2.0 |  4.0 |  3.0 | 10.0 |  3.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       4 |  3.0 |  5.0 |  4.0 | 11.0 |  4.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       5 |  4.0 |  6.0 |  5.0 | 12.0 |  5.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       6 |  5.0 |  6.0 |  6.0 | 13.0 |  6.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       7 |  7.0 |  8.0 |  0.0 | 14.0 |  7.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       8 |  7.0 |  9.0 |  1.0 | 15.0 |  8.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|       9 |  8.0 | 10.0 |  2.0 | 16.0 |  9.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      10 |  9.0 | 11.0 |  3.0 | 17.0 | 10.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      11 | 10.0 | 12.0 |  4.0 | 18.0 | 11.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      12 | 11.0 | 13.0 |  5.0 | 19.0 | 12.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      13 | 12.0 | 13.0 |  6.0 | 20.0 | 13.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      14 | 14.0 | 15.0 |  7.0 | 21.0 | 14.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      15 | 14.0 | 16.0 |  8.0 | 22.0 | 15.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      16 | 15.0 | 17.0 |  9.0 | 23.0 | 16.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      17 | 16.0 | 18.0 | 10.0 | 24.0 | 17.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      18 | 17.0 | 19.0 | 11.0 | 25.0 | 18.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      19 | 18.0 | 20.0 | 12.0 | 26.0 | 19.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      20 | 19.0 | 20.0 | 13.0 | 27.0 | 20.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      21 | 21.0 | 22.0 | 14.0 | 28.0 | 21.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      22 | 21.0 | 23.0 | 15.0 | 29.0 | 22.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      23 | 22.0 | 24.0 | 16.0 | 30.0 | 23.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      24 | 23.0 | 25.0 | 17.0 | 31.0 | 24.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      25 | 24.0 | 26.0 | 18.0 | 32.0 | 25.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      26 | 25.0 | 27.0 | 19.0 | 33.0 | 26.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      27 | 26.0 | 27.0 | 20.0 | 34.0 | 27.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      28 | 28.0 | 29.0 | 21.0 | 35.0 | 28.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      29 | 28.0 | 30.0 | 22.0 | 36.0 | 29.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      30 | 29.0 | 31.0 | 23.0 | 37.0 | 30.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      31 | 30.0 | 32.0 | 24.0 | 38.0 | 31.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      32 | 31.0 | 33.0 | 25.0 | 39.0 | 32.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      33 | 32.0 | 34.0 | 26.0 | 40.0 | 33.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      34 | 33.0 | 34.0 | 27.0 | 41.0 | 34.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      35 | 35.0 | 36.0 | 28.0 | 42.0 | 35.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      36 | 35.0 | 37.0 | 29.0 | 43.0 | 36.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      37 | 36.0 | 38.0 | 30.0 | 44.0 | 37.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      38 | 37.0 | 39.0 | 31.0 | 45.0 | 38.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      39 | 38.0 | 40.0 | 32.0 | 46.0 | 39.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      40 | 39.0 | 41.0 | 33.0 | 47.0 | 40.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      41 | 40.0 | 41.0 | 34.0 | 48.0 | 41.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      42 | 42.0 | 43.0 | 35.0 | 42.0 | 42.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      43 | 42.0 | 44.0 | 36.0 | 43.0 | 43.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      44 | 43.0 | 45.0 | 37.0 | 44.0 | 44.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      45 | 44.0 | 46.0 | 38.0 | 45.0 | 45.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      46 | 45.0 | 47.0 | 39.0 | 46.0 | 46.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      47 | 46.0 | 48.0 | 40.0 | 47.0 | 47.0 |\n",
      "+---------+------+------+------+------+------+\n",
      "|      48 | 47.0 | 48.0 | 41.0 | 48.0 | 48.0 |\n",
      "+---------+------+------+------+------+------+\n"
     ]
    }
   ],
   "source": [
    "acts = [\"L\", \"R\", \"U\", \"D\", \"S\"]\n",
    "show_table(env.reward,      acts, \"Reward table\")\n",
    "show_table(env.next_state,  acts, \"Next-state table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a01e5adb-869c-45b5-af59-43abfed441db",
   "metadata": {},
   "outputs": [],
   "source": [
    "discount = 0.9\n",
    "def init_v(env: GridWorld):\n",
    "    return np.zeros(env.nS)\n",
    "\n",
    "def init_pi(env: GridWorld):\n",
    "    pi = np.empty(env.nS)\n",
    "    for state in range(env.nS):\n",
    "        pi[state] = S\n",
    "    return pi\n",
    "        \n",
    "        \n",
    "def value_iteration(env: GridWorld):\n",
    "    #initialize current policy: Stay everywhere    \n",
    "    # pi is a nSx2 grid: for each state, what action we take. In this case, (0,0) for all\n",
    "    #initialize v = 0 for all S\n",
    "    # now make a q table with nSxnA\n",
    "    #loop over s\n",
    "        #for every a:\n",
    "            #q[s,a] = immediate reward for the action from reward table + discount rate x v(next state for that action)\n",
    "        #take maximum a and then set pi[s] = a\n",
    "        #then set v[s] to the return of chosing this max a\n",
    "\n",
    "    pi = init_pi(env)\n",
    "    v_table = init_v(env)\n",
    "    q_table = np.full((env.nS, env.nA), 0, dtype=float)\n",
    "    diff = float('inf')\n",
    "    while diff>0.01:\n",
    "        v_table_new = np.copy(v_table)\n",
    "        for state in range (env.nS):\n",
    "            max_reward = float('-inf')\n",
    "            for action in range (env.nA):\n",
    "                qvalue = env.reward[state][action] + discount*v_table[env.next_state[state][action]]\n",
    "                q_table[state][action] = qvalue\n",
    "                if qvalue>=max_reward:\n",
    "                    max_reward = qvalue\n",
    "                    pi[state] = action\n",
    "            v_table_new[state] = max_reward\n",
    "        diff = np.sum(np.absolute(v_table_new-v_table))\n",
    "        v_table = np.copy(v_table_new)\n",
    "\n",
    "    ##Recreate path\n",
    "    # path = recreate_path(pi, env)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return pi, v_table, q_table\n",
    "\n",
    "def recreate_path(pi: np.array, env: GridWorld):\n",
    "    path = np.zeros((env.rows,env.cols))\n",
    "    ctr = 0\n",
    "    for i in range(env.rows):\n",
    "        for j in range (env.cols):\n",
    "            path[i][j] = pi[ctr]\n",
    "            ctr+=1\n",
    "        \n",
    "    return path\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a0b82091-2116-4b2f-85e3-429c9f928f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Policy iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "105476c3-7f5e-40a1-aa64-3188c86b527b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+\n",
      "| H | H | H | · | · | · | · |\n",
      "+---+---+---+---+---+---+---+\n",
      "| · | · | · | · | · | · | · |\n",
      "+---+---+---+---+---+---+---+\n",
      "| · | · | · | · | H | · | · |\n",
      "+---+---+---+---+---+---+---+\n",
      "| H | · | · | · | · | · | S |\n",
      "+---+---+---+---+---+---+---+\n",
      "| · | H | · | · | · | H | · |\n",
      "+---+---+---+---+---+---+---+\n",
      "| · | G | · | · | · | · | · |\n",
      "+---+---+---+---+---+---+---+\n",
      "| H | · | · | · | · | · | · |\n",
      "+---+---+---+---+---+---+---+\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2b374b80-caf6-4c99-bdb1-e0acc39067c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy(pi: np.ndarray, env: GridWorld, \n",
    "                    error: float = 1e-10) -> np.ndarray:\n",
    "    V = np.zeros(env.nS)\n",
    "    while True:\n",
    "        delta = 0.0\n",
    "        for s in range(env.nS):\n",
    "            a      = int(pi[s])\n",
    "            v_new  = env.reward[s, a] + discount * V[env.next_state[s, a]]\n",
    "            delta  = max(delta, abs(v_new - V[s]))\n",
    "            V[s]   = v_new\n",
    "        if delta < error:\n",
    "            break\n",
    "    return V\n",
    "\n",
    "\n",
    "def policy_iteration(env: GridWorld):\n",
    "    pi = np.zeros(env.nS, dtype=int)      # arbitrary start, say all 0 = Left\n",
    "    while True:\n",
    "        V = evaluate_policy(pi, env)\n",
    "        policy_stable = True\n",
    "        for s in range(env.nS):\n",
    "            # one-step look-ahead for all actions\n",
    "            q_sa = env.reward[s] + discount * V[env.next_state[s]]\n",
    "            best_a = int(np.argmax(q_sa))\n",
    "            if best_a != pi[s]:\n",
    "                policy_stable = False\n",
    "                pi[s] = best_a\n",
    "        if policy_stable:\n",
    "            break\n",
    "    return pi, V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fd290f65-275f-438f-9637-28a3c9df7aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, v = policy_iteration(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "68c19033-b9ea-4003-a301-ebbe582d30ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 3., 3., 3., 3., 3., 3.],\n",
       "       [1., 3., 3., 3., 0., 3., 3.],\n",
       "       [1., 3., 3., 3., 3., 3., 3.],\n",
       "       [3., 3., 3., 3., 3., 0., 3.],\n",
       "       [3., 3., 3., 3., 3., 3., 3.],\n",
       "       [1., 4., 0., 0., 0., 0., 0.],\n",
       "       [1., 2., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recreate_path(p, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "71c0fb2f-f1f0-442d-a3f2-d1dad4608fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+\n",
      "| H | H | H | · | · | · | · |\n",
      "+---+---+---+---+---+---+---+\n",
      "| · | · | · | · | · | · | · |\n",
      "+---+---+---+---+---+---+---+\n",
      "| · | · | · | · | H | · | · |\n",
      "+---+---+---+---+---+---+---+\n",
      "| H | · | · | · | · | · | S |\n",
      "+---+---+---+---+---+---+---+\n",
      "| · | H | · | · | · | H | · |\n",
      "+---+---+---+---+---+---+---+\n",
      "| · | G | · | · | · | · | · |\n",
      "+---+---+---+---+---+---+---+\n",
      "| H | · | · | · | · | · | · |\n",
      "+---+---+---+---+---+---+---+\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca2110-df54-407c-82a1-3d6894a43ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
